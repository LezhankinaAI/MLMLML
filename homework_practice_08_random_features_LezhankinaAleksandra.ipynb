{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 05.02.2021\n",
    "\n",
    "Мягкий дедлайн: 01:59MSK 21.02.2021\n",
    "\n",
    "Жесткий дедлайн: 01:59MSK 24.02.2021\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EstQmLkGNAAm",
    "outputId": "552af4ef-bd29-4319-c071-e9cd6baeefc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\александра\\appdata\\roaming\\python\\python37\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\александра\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\александра\\appdata\\roaming\\python\\python37\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "          self.use_PCA = PCA(n_components=self.new_dim)\n",
    "          df = self.use_PCA.fit(X)\n",
    "          df = df.transform(X)\n",
    "        else:\n",
    "          df = X.copy()\n",
    "          self.new_dim = df.shape[1]\n",
    "\n",
    "        pairs = (np.square(df.shape[0]) - 1) / 2\n",
    "        fst = np.random.randint(0, df.shape[0], min(1000000, pairs))\n",
    "        scd = np.random.randint(0, df.shape[0], min(1000000, pairs))\n",
    "        ind = fst != scd\n",
    "        fst = fst[ind]\n",
    "        scd = scd[ind]\n",
    "        sigma2 = np.median(np.sum(np.square(df[fst] - df[scd]), axis=1))\n",
    "        self.w = np.random.normal(0, 1 / np.sqrt(sigma2), self.new_dim * self.n_features)\\\n",
    "            .reshape(self.n_features, self.new_dim)\n",
    "        self.b = np.random.uniform(-m.pi, m.pi, self.n_features)\n",
    "        phi = np.cos(np.dot(df, self.w.T) + self.b)\n",
    "        if self.classifier == 'logreg':\n",
    "            self.classifier = LogisticRegression(max_iter=10000)\n",
    "        else:\n",
    "            self.classifier = LinearSVC(max_iter=10000)\n",
    "        self.classifier.fit(phi, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA is not False:\n",
    "            df = self.use_PCA.transform(X)\n",
    "        else:\n",
    "            df = X.copy()\n",
    "        phi = np.cos(np.dot(df, self.w.T) + self.b)\n",
    "        return self.classifier.predict_proba(phi)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA is not False:\n",
    "            df = self.use_PCA.transform(X)\n",
    "        else:\n",
    "            df = X.copy()\n",
    "        phi = np.cos(np.dot(df, self.w.T) + self.b)\n",
    "        return self.classifier.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uqIFk3-NAAu",
    "outputId": "cd594ea1-86ed-402b-ce35-1275f2654fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "task = RFFPipeline(classifier='logreg')\n",
    "task.fit(x_train, y_train)\n",
    "y_pred = task.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qN8LUlJgK-hV",
    "outputId": "7d95b269-5fdc-458b-c1cf-5ed4161d2317"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF SVM accuracy: 0.8778 \n",
      " fit time: 2402.9886565208435 \n",
      " predict time: 0.5070657730102539\n"
     ]
    }
   ],
   "source": [
    "import time as t\n",
    "\n",
    "task1 = RFFPipeline(classifier='svm')\n",
    "t1 = t.time()\n",
    "task1.fit(x_train, y_train)\n",
    "t2 = t.time()\n",
    "y_pred1 = task1.predict(x_test)\n",
    "t3 = t.time()\n",
    "print('RFF SVM accuracy:', accuracy_score(y_test, y_pred1), '\\n', \n",
    "     'fit time:', t2 - t1, '\\n',\n",
    "     'predict time:', t3 - t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z96muFFnNAA0",
    "outputId": "14f50bfb-b7c3-41b5-987f-77d6fa88be98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM accuracy: 0.7434 \n",
      " fit time: 2998.98811006546 \n",
      " predict time: 0.03526806831359863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "task2 = LinearSVC(max_iter=10000)\n",
    "t1 = t.time()\n",
    "task2.fit(x_train, y_train)\n",
    "t2 = t.time()\n",
    "y_pred2 = task2.predict(x_test)\n",
    "t3 = t.time()\n",
    "print('Linear SVM accuracy:', accuracy_score(y_test, y_pred2), '\\n', \n",
    "     'fit time:', t2 - t1, '\\n',\n",
    "     'predict time:', t3 - t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge7Xqe69NAA0",
    "outputId": "eae8e85f-0605-4bab-b030-13dd59defe4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n",
      "\u001b[K     |████████████████████████████████| 65.8MB 71kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.24.4\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAX5PFjdNAA1",
    "outputId": "fafd3260-926a-4e8a-da99-fb333734c507"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:57<07:55, 237.70s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [11:45<05:06, 306.58s/it]\u001b[A\n",
      "100%|██████████| 3/3 [26:49<00:00, 536.65s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:38<07:16, 218.50s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [11:15<04:50, 290.07s/it]\u001b[A\n",
      "100%|██████████| 3/3 [26:55<00:00, 538.37s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [03:53<07:46, 233.48s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [11:39<05:03, 303.24s/it]\u001b[A\n",
      "100%|██████████| 3/3 [26:18<00:00, 526.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catbost with eta: 0.1 and n_estimators: 2000 \n",
      " accuracy: 0.8802 \n",
      " fit time: 904.7086944580078 \n",
      " predict time: 0.20457911491394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(x_train)\n",
    "X_train = pca.transform(x_train)\n",
    "X_test = pca.transform(x_test)\n",
    "learning_rate = [0.1, 0.05, 0.01]\n",
    "n_estimators = [500, 1000, 2000]\n",
    "models = []\n",
    "accuracies = []\n",
    "for eta in learning_rate:\n",
    "  for trees in tqdm(n_estimators):\n",
    "    model = CatBoostClassifier(\n",
    "      random_seed=42,\n",
    "      logging_level='Silent',\n",
    "      learning_rate=eta,\n",
    "      n_estimators=trees\n",
    "    )\n",
    "    t1 = t.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    t2 = t.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    t3 = t.time()\n",
    "    models.append((eta, trees, t2 - t1, t3 - t2))\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "ind = np.argmax(accuracies)\n",
    "print('Catbost with eta:', models[ind][0], 'and n_estimators:', models[ind][1], '\\n',\n",
    "      'accuracy:', accuracies[ind], '\\n', \n",
    "      'fit time:', models[ind][2], '\\n',\n",
    "      'predict time:', models[ind][3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TOK-lxgjBV6"
   },
   "source": [
    "Подведём итоги:\n",
    "\n",
    "Самый плохой вариант во всех смыслах -- обычный линейный SVM. Он проигрывает и по времени обучения и по качеству. Вообще я не смогла подобрать такое число итераций, чтобы метод сходился и работал за конечное время. При 100 000 итераций я за сутки не дождалась окончания работы и решила оставить так. Это происходит потому, что выборка линейно неразделима.\n",
    "\n",
    "Ядровой SVM даёт значительно лучшее качество, но время предсказания дольше. \n",
    "\n",
    "Самое лучшее качество дает Бустинг с PCA. По времени он обучается тоже быстро, но в подсчетах не учитывался подбор длины шага и числа деревьев, возможно при выборе гиперпараметров для других методов, в частности для Ядрового SVM, там качество оказалось бы еще лучше.\n",
    "\n",
    "Очевидно, что преобразование признаков имеет смысл, и его стоит использовать, когда нет необходимости сделать предсказание быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2QIHIMbK-hW",
    "outputId": "67c0c97a-af55-40da-ff29-d013447c6f5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF SVM without PCA accuracy: 0.1004 \n",
      " fit time: 1007.1245582103729 \n",
      " predict time: 0.9164285659790039\n"
     ]
    }
   ],
   "source": [
    "task = RFFPipeline(classifier='svm', use_PCA=False)\n",
    "indexes = np.random.choice(x_train.shape[0], int(x_train.shape[0] * 0.5), replace = False)\n",
    "X_train = x_train[indexes]\n",
    "Y_train = y_train[indexes]\n",
    "t1 = t.time()\n",
    "task.fit(X_train, Y_train)\n",
    "t2 = t.time()\n",
    "y_pred1 = task.predict(x_test)\n",
    "t3 = t.time()\n",
    "print('RFF SVM without PCA accuracy:', accuracy_score(y_test, y_pred1), '\\n', \n",
    "     'fit time:', t2 - t1, '\\n',\n",
    "     'predict time:', t3 - t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD83Cp5F12V1"
   },
   "source": [
    "При неиспользовании PCA качество становится заметно хуже. Скорее всего, алгоритм переобучается, тк подгоняется под слишком большое число признаков. А также признаки становятся слишком рандомными и нелогичными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFR0gPdLkN8a"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "x3dKk11fjLWu",
    "outputId": "8f11211c-420d-4ddf-8a02-7867e85e7faf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = np.arange(200, 2000, 150, dtype=int)\n",
    "indexes = np.random.choice(x_train.shape[0], int(x_train.shape[0] * 0.5), replace = False)\n",
    "X_train = x_train[indexes]\n",
    "Y_train = y_train[indexes]\n",
    "accuracies = []\n",
    "for feature in features:\n",
    "  model = RFFPipeline(n_features=feature, classifier='svm')\n",
    "  model.fit(X_train, Y_train)\n",
    "  accuracies.append(accuracy_score(y_test, model.predict(x_test)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(features, accuracies)\n",
    "\n",
    "ax.set(xlabel='n_features', ylabel='accuracy',\n",
    "       title='Dependence of accuracy on number of features')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U3cKkkokO8S"
   },
   "source": [
    "Заметим, что при увеличении n_features, качество также постепенно увеличивается. В данном случае максимальным значением гиперпараметра я выставила 2000 и выхода на плато не зафиксировала. Алгоритм при этом значении уже работал достаточно долго, поэтому увеличивать еще больше я не стала. Из той тенденции, что мы можем наблюдать сейчас, видно, что где-то с значения 800 n_features кривая начинает колебаться. Скорее всего, так бы продолжалось и далее, только с меньшим диапазоном. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxE2KspGjLhR",
    "outputId": "440ada5a-cb6c-4507-8fc8-accbcf77c330"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.8802\n"
     ]
    }
   ],
   "source": [
    "model = RFFPipeline(classifier='svm')\n",
    "model.fit(x_train, y_train)\n",
    "print('SVM accuracy:', accuracy_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivqmPXn9kPgg"
   },
   "source": [
    "В самом первом запуске алгоритма, для логистической регрессии, качество равнялось 0,8795. Для SVM оно стало незначительно лучше: 0,8802. Таким образом, Ядровой SVM работает немного лучше, но разница небольшая, поэтому, можно сказать, неважно, какой классификатор использовать. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class RFFPipeline_new(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier=LogisticRegression(), phi='cos'):\n",
    "        \"\"\"\n",
    "        classiffier is one of the svm, logreg, tree, forest\n",
    "        phi is one of the cos, sign, mod\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.phi = phi\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.use_PCA:\n",
    "            self.use_PCA = PCA(n_components=self.new_dim)\n",
    "            df = self.use_PCA.fit(X)\n",
    "            df = df.transform(X)\n",
    "        else:\n",
    "            df = X.copy()\n",
    "            self.new_dim = df.shape[1]\n",
    "\n",
    "        pairs = (np.square(df.shape[0]) - 1) / 2\n",
    "        fst = np.random.randint(0, df.shape[0], min(1000000, pairs))\n",
    "        scd = np.random.randint(0, df.shape[0], min(1000000, pairs))\n",
    "        ind = fst != scd\n",
    "        fst = fst[ind]\n",
    "        scd = scd[ind]\n",
    "        sigma2 = np.median(np.sum(np.square(df[fst] - df[scd]), axis=1))\n",
    "        self.w = np.random.normal(0, 1 / np.sqrt(sigma2), self.new_dim * self.n_features)\\\n",
    "            .reshape(self.n_features, self.new_dim)\n",
    "        self.b = np.random.uniform(-m.pi, m.pi, self.n_features)\n",
    "        if self.phi == 'cos':\n",
    "          phi = np.cos(np.dot(df, self.w.T) + self.b)\n",
    "        elif self.phi == 'sign':\n",
    "          phi = np.sign(np.dot(df, self.w.T) + self.b)\n",
    "        elif self.phi == 'mod':\n",
    "          phi = (np.dot(df, self.w.T) + self.b) % 10\n",
    "        elif self.phi == 'e':\n",
    "          phi = np.exp(-(np.dot(df, self.w.T) + self.b))\n",
    "        self.classifier.fit(phi, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.use_PCA is not False:\n",
    "            df = self.use_PCA.transform(X)\n",
    "        else:\n",
    "            df = X.copy()\n",
    "        if self.phi == 'cos':\n",
    "          phi = np.cos(np.dot(df, self.w.T) + self.b)\n",
    "        elif self.phi == 'sign':\n",
    "          phi = np.sign(np.dot(df, self.w.T) + self.b)\n",
    "        elif self.phi == 'mod':\n",
    "          phi = (np.dot(df, self.w.T) + self.b) % 10\n",
    "        elif self.phi == 'e':\n",
    "          phi = np.exp(-(np.dot(df, self.w.T) + self.b))\n",
    "        return self.classifier.predict_proba(phi)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.use_PCA is not False:\n",
    "            df = self.use_PCA.transform(X)\n",
    "        else:\n",
    "            df = X.copy()\n",
    "        if self.phi == 'cos':\n",
    "          phi = np.cos(np.dot(df, self.w.T) + self.b)\n",
    "        elif self.phi == 'sign':\n",
    "          phi = np.sign(np.dot(df, self.w.T) + self.b)\n",
    "        elif self.phi == 'mod':\n",
    "          phi = (np.dot(df, self.w.T) + self.b) % 10\n",
    "        elif self.phi == 'e':\n",
    "          phi = np.exp(-(np.dot(df, self.w.T) + self.b))\n",
    "        return self.classifier.predict(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLHgJYwHaY-N",
    "outputId": "9152acb9-a533-4bb8-d3d2-2e81ae45e55e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [01:46<05:19, 106.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      " phi: cos \n",
      " accuracy: 0.8589\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [02:11<02:44, 82.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      " phi: cos \n",
      " accuracy: 0.8512\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [06:13<02:09, 129.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=12, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') \n",
      " max_depth: None \n",
      " min_samples_leaf: 12 \n",
      " phi: cos \n",
      " accuracy: 0.7652\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [07:19<00:00, 109.97s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) \n",
      " n_estimators: 100 \n",
      " phi: cos \n",
      " accuracy: 0.8434\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [02:13<06:39, 133.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      " phi: sign \n",
      " accuracy: 0.8063\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [02:38<03:21, 100.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      " phi: sign \n",
      " accuracy: 0.8144\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [03:20<01:23, 83.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=12, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') \n",
      " max_depth: None \n",
      " min_samples_leaf: 12 \n",
      " phi: sign \n",
      " accuracy: 0.7528\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:33<00:00, 53.40s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) \n",
      " n_estimators: 100 \n",
      " phi: sign \n",
      " accuracy: 0.8286\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [02:24<07:14, 144.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      " phi: mod \n",
      " accuracy: 0.8011\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [02:50<03:38, 109.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      " phi: mod \n",
      " accuracy: 0.8203\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [06:41<02:25, 145.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=12, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') \n",
      " max_depth: None \n",
      " min_samples_leaf: 12 \n",
      " phi: mod \n",
      " accuracy: 0.7639\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [07:48<00:00, 117.02s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) \n",
      " n_estimators: 100 \n",
      " phi: mod \n",
      " accuracy: 0.8407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [02:46<08:19, 166.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      " phi: e \n",
      " accuracy: 0.827\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [03:11<04:08, 124.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      " phi: e \n",
      " accuracy: 0.8408\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [07:07<02:37, 157.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=12, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') \n",
      " max_depth: None \n",
      " min_samples_leaf: 12 \n",
      " phi: e \n",
      " accuracy: 0.7749\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:14<00:00, 123.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False) \n",
      " n_estimators: 100 \n",
      " phi: e \n",
      " accuracy: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classes = [LinearSVC(), LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "phi = ['cos', 'sign', 'mod', 'e']\n",
    "indexes = np.random.choice(x_train.shape[0], int(x_train.shape[0] * 0.3), replace = False)\n",
    "X_train = x_train[indexes]\n",
    "Y_train = y_train[indexes]\n",
    "\n",
    "for f in phi:\n",
    "  for i in tqdm(range(4)):\n",
    "    print('\\n')\n",
    "    if i == 2:\n",
    "      acc = 0\n",
    "      d = None\n",
    "      l = None\n",
    "      cl = None\n",
    "      for i, max_depth in enumerate([2, 8, None]):\n",
    "        for j, min_samples_leaf in enumerate([12, 5, 2]):\n",
    "          clas = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "          model = RFFPipeline_new(classifier=clas, phi=f, use_PCA=True)\n",
    "          model.fit(X_train, Y_train)\n",
    "          y_pred = model.predict(x_test)\n",
    "          if accuracy_score(y_test, y_pred) > acc:\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            d = max_depth\n",
    "            l = min_samples_leaf\n",
    "            cl = clas\n",
    "      print('\\nclassification:', cl, '\\n',\n",
    "            'max_depth:', d, '\\n',\n",
    "            'min_samples_leaf:', l, '\\n',\n",
    "            'phi:', f, '\\n',\n",
    "            'accuracy:', acc)\n",
    "    elif i == 3:\n",
    "      acc = 0\n",
    "      e = None\n",
    "      cl = None\n",
    "      estimators = 10**np.arange(1, 3)\n",
    "      for estimator in estimators:\n",
    "        clas = RandomForestClassifier(n_jobs=-1, n_estimators=estimator)\n",
    "        model = RFFPipeline_new(classifier=clas, phi=f, use_PCA=True)\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        if accuracy_score(y_test, y_pred) > acc:\n",
    "          acc = accuracy_score(y_test, y_pred)\n",
    "          e = estimator\n",
    "          cl = clas\n",
    "      print('\\nclassification:', cl, '\\n',\n",
    "            'n_estimators:', e, '\\n',\n",
    "            'phi:', f, '\\n',\n",
    "            'accuracy:', acc)\n",
    "    else:\n",
    "      model = RFFPipeline_new(classifier=classes[i], phi=f, use_PCA=True)\n",
    "      model.fit(X_train, Y_train)\n",
    "      y_pred = model.predict(x_test)\n",
    "      print('\\nclassification:', classes[i], '\\n',\n",
    "            'phi:', f, '\\n',\n",
    "            'accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6zU46-CJl6B"
   },
   "source": [
    "В данном случае я по максимуму ускоряла работу алгоритма (уменьшение числа итераций, уменьшение обучающей выборки), тк без этого ячейка работала бы сто лет, поэтому результаты не превзошли то, что уже было. (Результаты SVM и LogReg не совпадают с тем, что было, так что это точно ускоряющие изменения так повлияли, без них, качество наверняка было бы заметно лучше).\n",
    "\n",
    "Здесь я добавила такие функции, как e^-(скалярное произведение), mod 10 от скалярного произведения. Новые классификаторы: Дерево решений и Случайный лес с подбором гиперпараметров.\n",
    "\n",
    "Среди текущих лучшим по-прежнему является Ядровой SVM с качеством 0.8589 с phi с косинусом. Не далеко ушла Логистическая регрессия на той же функции с качеством 0.8512. Чуть хуже Случайный лес: 0.8434. Этот классификатор показал неплохие результаты на всех функциях (причём лучший свой результат с экспонентой), поэтому, наверное, его можно выделить как самый подходящий.\n",
    "\n",
    "Решающие деревья везде показали нелучший результат, так что этот классификатор нам точно не подходит. \n",
    "\n",
    "Функции, на которых стоит обратить внимание: cos, mod 10, exp. Их результаты отличались в среднем на сотые. \n",
    "\n",
    "Опять же, эксперимент был бы честнее, если бы использовались одинаковые по размеру выборки для обучения, но дедлайн, время поджимает :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_xpqh_VgCNi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features-LezhankinaAleksandra.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
